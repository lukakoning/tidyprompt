<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Prompt and empower your LLM, the tidy way • tidyprompt</title>
<script src="deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet">
<link href="deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet">
<script src="deps/headroom-0.11.0/headroom.min.js"></script><script src="deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="deps/search-1.0.0/fuse.min.js"></script><script src="deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="pkgdown.js"></script><meta property="og:title" content="Prompt and empower your LLM, the tidy way">
<meta name="description" content="The tidyprompt package allows users to prompt and empower their large language models (LLMs) in a tidy way. It provides a framework to construct LLM prompts using tidyverse-inspired piping syntax, with a library of pre-built prompt wrappers and the option to build custom ones. Additionally, it supports structured LLM output extraction and validation, with automatic feedback and retries if necessary. Moreover, it enables specific LLM reasoning modes, autonomous R function calling for LLMs, and compatibility with any LLM provider.">
<meta property="og:description" content="The tidyprompt package allows users to prompt and empower their large language models (LLMs) in a tidy way. It provides a framework to construct LLM prompts using tidyverse-inspired piping syntax, with a library of pre-built prompt wrappers and the option to build custom ones. Additionally, it supports structured LLM output extraction and validation, with automatic feedback and retries if necessary. Moreover, it enables specific LLM reasoning modes, autonomous R function calling for LLMs, and compatibility with any LLM provider.">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="index.html">tidyprompt</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="articles/example_usage.html">Example usage</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/tjarkvandemerwe/tidyprompt/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-home">
<div class="row">
  <main id="main" class="col-md-9"><div class="section level1">
<div class="page-header"><h1 id="tidyprompt">tidyprompt<a class="anchor" aria-label="anchor" href="#tidyprompt"></a>
</h1></div>
<!-- badges: start -->
<!-- badges: end -->
<p><code>tidyprompt</code> is an R package to prompt and empower your large language models (LLMs), the tidy way.</p>
<p>Key features of <code>tidyprompt</code> are:</p>
<ul>
<li><p><strong>tidy prompting</strong>: Quickly and elegantly construct prompts for LLMs, using piping syntax (inspired by the <code>tidyverse</code>). Wrap a base prompt in prompt wrappers to influence how the LLM handles the prompt. A library of pre-built prompt wrappers is included, but you can also write your own.</p></li>
<li><p><strong>structured output</strong>: Extract structured output from the LLM’s response, and validate it. Automatic retries with feedback to the LLM, if the output is not as expected.</p></li>
<li><p><strong>reasoning modes</strong>: Make your LLM answer in a specific mode, such as chain-of-thought or ReAct (Reasoning and Acting) modes.</p></li>
<li><p><strong>function calling</strong>: Give your LLM the ability to autonomously call R functions (‘tools’). With this, the LLM can retrieve information or take other actions.</p></li>
<li><p><strong>compatible with all LLM providers</strong>: Usable with any LLM provider that supports chat completion. Use included LLM providers such as Ollama (on your local PC or your own server) or the OpenAI API. Or easily write a hook for any other LLM provider.</p></li>
</ul>
<div class="section level2">
<h2 id="installation">Installation<a class="anchor" aria-label="anchor" href="#installation"></a>
</h2>
<p>You can install the development version of tidyprompt from <a href="https://github.com/tjarkvandemerwe/tidyprompt" class="external-link">GitHub</a> with:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># install.packages("remotes")</span></span>
<span><span class="fu">remotes</span><span class="fu">::</span><span class="fu"><a href="https://remotes.r-lib.org/reference/install_github.html" class="external-link">install_github</a></span><span class="op">(</span><span class="st">"tjarkvandemerwe/tidyprompt"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="example-usage">Example usage<a class="anchor" aria-label="anchor" href="#example-usage"></a>
</h2>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/tjarkvandemerwe/tidyprompt" class="external-link">tidyprompt</a></span><span class="op">)</span></span></code></pre></div>
<div class="section level3">
<h3 id="setup-an-llm-provider">Setup an LLM provider<a class="anchor" aria-label="anchor" href="#setup-an-llm-provider"></a>
</h3>
<p><code>tidyprompt</code> can be used with any LLM provider capable of completing a chat.</p>
<p>At the moment, <code>tidyprompt</code> includes pre-built functions to connect with Ollama and the OpenAI API.</p>
<p>With the <code>create_llm_provider</code> function, you can easily write a hook for any other LLM provider. You could make API calls using the <code>httr</code> package or use another R package that already has a hook for the LLM provider you want to use.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Ollama running on local PC</span></span>
<span><span class="va">ollama</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/create_ollama_llm_provider.html">create_ollama_llm_provider</a></span><span class="op">(</span></span>
<span>  parameters <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>model <span class="op">=</span> <span class="st">"llama3.1:8b"</span>, url <span class="op">=</span> <span class="st">"http://localhost:11434/api/chat"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># OpenAI API</span></span>
<span><span class="va">openai</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/create_openai_llm_provider.html">create_openai_llm_provider</a></span><span class="op">(</span></span>
<span>  parameters <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>model <span class="op">=</span> <span class="st">"gpt-4o-mini"</span>, api_key <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Sys.getenv.html" class="external-link">Sys.getenv</a></span><span class="op">(</span><span class="st">"OPENAI_API_KEY"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create your own LLM provider hook using create_llm_provider(); </span></span>
<span><span class="co">#   see ?create_llm_provider for more information, and take a look at</span></span>
<span><span class="co">#   the source code of create_ollama_llm_provider() and create_openai_llm_provider()</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="basic-prompting">Basic prompting<a class="anchor" aria-label="anchor" href="#basic-prompting"></a>
</h3>
<p>A simple string serves as the base for a prompt.</p>
<p>By adding prompt wrappers, you can influence various aspects of how the LLM handles the prompt, while verifying that the output is structured and valid (including retries with feedback to the LLM if it is not).</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="st">"Hi there!"</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="reference/send_prompt.html">send_prompt</a></span><span class="op">(</span><span class="va">ollama</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "It's nice to meet you. Is there something I can help you with or would you like to chat?"</span></span></code></pre></div>
<p><code>add_text</code> is a simple example of a prompt wrapper. It simply adds some text at the end of the base prompt.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="st">"Hi there!"</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="reference/add_text.html">add_text</a></span><span class="op">(</span><span class="st">"What is a large language model? Explain in 10 words."</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="reference/send_prompt.html">send_prompt</a></span><span class="op">(</span><span class="va">ollama</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "Complex computer program trained on vast texts to generate human-like responses."</span></span></code></pre></div>
<p>You can also construct the final prompt text, without sending it to an LLM provider.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="st">"Hi there!"</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="reference/add_text.html">add_text</a></span><span class="op">(</span><span class="st">"What is a large language model? Explain in 10 words."</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="reference/construct_prompt_text.html">construct_prompt_text</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; Hi there!</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; What is a large language model? Explain in 10 words.</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="retrieving-output-in-a-specific-format">Retrieving output in a specific format<a class="anchor" aria-label="anchor" href="#retrieving-output-in-a-specific-format"></a>
</h3>
<p>Using prompt wrappers, you can force the LLM to return the output in a specific format. You can also extract the output to turn it from a character into another data type.</p>
<p>For instance, the <code>answer_as_integer</code> prompt wrapper will force the LLM to return an integer.</p>
<p>To achieve this, the prompt wrapper will add some text to the base prompt, asking the LLM to reply with an integer. However, the prompt wrapper does more: it also will attempt to extract and validate the integer from the LLM’s response. If extraction or validation fails, feedback is sent back to the LLM, after which the LLM can retry answering the prompt.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="st">"What is 2 + 2?"</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="reference/answer_as_integer.html">answer_as_integer</a></span><span class="op">(</span>add_instruction_to_prompt <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="reference/send_prompt.html">send_prompt</a></span><span class="op">(</span><span class="va">ollama</span>, verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; --- Sending message to LLM-provider: ---</span></span>
<span><span class="co">#&gt; What is 2 + 2?</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; You must answer with only an integer (use no other characters).</span></span>
<span><span class="co">#&gt; --- Received response from LLM-provider: ---</span></span>
<span><span class="co">#&gt; 4</span></span>
<span><span class="co">#&gt; [1] 4</span></span></code></pre></div>
<p>Below is an example of a prompt which will initially fail, but will succeed after a retry.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="st">"What is 2 + 2?"</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="reference/add_text.html">add_text</a></span><span class="op">(</span><span class="st">"Please write out your reply in words, use no numbers."</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="reference/answer_as_integer.html">answer_as_integer</a></span><span class="op">(</span>add_instruction_to_prompt <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="reference/send_prompt.html">send_prompt</a></span><span class="op">(</span><span class="va">ollama</span>, verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; --- Sending message to LLM-provider: ---</span></span>
<span><span class="co">#&gt; What is 2 + 2?</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Please write out your reply in words, use no numbers.</span></span>
<span><span class="co">#&gt; --- Received response from LLM-provider: ---</span></span>
<span><span class="co">#&gt; Four.</span></span>
<span><span class="co">#&gt; --- Sending message to LLM-provider: ---</span></span>
<span><span class="co">#&gt; You must answer with only an integer (use no other characters).</span></span>
<span><span class="co">#&gt; --- Received response from LLM-provider: ---</span></span>
<span><span class="co">#&gt; 4</span></span>
<span><span class="co">#&gt; [1] 4</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="adding-a-reasoning-mode-to-the-llm">Adding a reasoning mode to the LLM<a class="anchor" aria-label="anchor" href="#adding-a-reasoning-mode-to-the-llm"></a>
</h3>
<p>Prompt wrappers may also be used to add a reasoning mode to the LLM. It is hypothesized that this could improve the LLM’s performance on more complex tasks.</p>
<p>For instance, function <code>set_mode_chainofthought</code> will add chain of thought reasoning mode to the LLM. This wraps the base prompt within a request for the LLM to reason step by step, asking it to provide the final answer within ‘FINISH[<final answer here>]’. An extraction function then ensures only the final answer is returned.</final></p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="st">"What is 2 + 2?"</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">set_mode_chainofthought</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="reference/answer_as_integer.html">answer_as_integer</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="reference/send_prompt.html">send_prompt</a></span><span class="op">(</span><span class="va">ollama</span>, verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; --- Sending message to LLM-provider: ---</span></span>
<span><span class="co">#&gt; You are given a user's prompt.</span></span>
<span><span class="co">#&gt; To answer the user's prompt, you need to think step by step to arrive at a final answer.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ----- START OF USER'S PROMPT -----</span></span>
<span><span class="co">#&gt; What is 2 + 2?</span></span>
<span><span class="co">#&gt; ----- END OF USER'S PROMPT -----</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; What are the steps you would take to answer the user's prompt?</span></span>
<span><span class="co">#&gt; Describe your thought process in the following format:</span></span>
<span><span class="co">#&gt;   &gt;&gt; step 1: &lt;step 1 description&gt;</span></span>
<span><span class="co">#&gt;   &gt;&gt; step 2: &lt;step 2 description&gt;</span></span>
<span><span class="co">#&gt;   (etc.)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; When you are done, you must type:</span></span>
<span><span class="co">#&gt; FINISH[&lt;put here your final answer to the user's prompt&gt;]</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Make sure your final answer follows the logical conclusion of your thought process.</span></span>
<span><span class="co">#&gt; --- Received response from LLM-provider: ---</span></span>
<span><span class="co">#&gt; &gt;&gt; step 1: Identify the mathematical operation in the prompt, which is a simple addition problem.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; &gt;&gt; step 2: Recall the basic arithmetic fact that 2 + 2 equals a specific numerical value.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; &gt;&gt; step 3: Apply this knowledge to determine the result of the addition problem, using the known facts about numbers and their operations.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; &gt;&gt; step 4: Conclude that based on this mathematical understanding, the solution to the prompt "What is 2 + 2?" is a fixed numerical quantity.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; FINISH[4]</span></span>
<span><span class="co">#&gt; [1] 4</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="giving-tools-to-the-llm-autonomous-function-calling">Giving tools to the LLM (autonomous function-calling)<a class="anchor" aria-label="anchor" href="#giving-tools-to-the-llm-autonomous-function-calling"></a>
</h3>
<p>With <code>tidyprompt</code>, you can define R functions and give the LLM the ability to call them. This enables the LLM to retrieve additional information or take other actions.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="co"># Define a function that returns fake data about the temperature in a location</span></span>
<span>  <span class="va">temperature_in_location</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span></span>
<span>    <span class="va">location</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Amsterdam"</span>, <span class="st">"Utrecht"</span>, <span class="st">"Enschede"</span><span class="op">)</span>,</span>
<span>    <span class="va">unit</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Celcius"</span>, <span class="st">"Fahrenheit"</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="co">#' llm_tool::name temperature_in_location</span></span>
<span>    <span class="co">#'</span></span>
<span>    <span class="co">#' llm_tool::description Get the temperature in a location</span></span>
<span>    <span class="co">#'</span></span>
<span>    <span class="co">#' llm_tool::param location Location, must be one of: "Amsterdam", "Utrecht", "Enschede"</span></span>
<span>    <span class="co">#' llm_tool::param unit Unit, must be one of: "Celcius", "Fahrenheit"</span></span>
<span>    <span class="co">#'</span></span>
<span>    <span class="co">#' llm_tool::return The temperature in the specified location and unit</span></span>
<span>    <span class="co">#'</span></span>
<span>    <span class="co">#' llm_tool::example</span></span>
<span>    <span class="co">#' temperature_in_location("Amsterdam", "Fahrenheit")</span></span>
<span>    </span>
<span>    <span class="co"># As shown above, one can use docstring-like text to document the function.</span></span>
<span>    <span class="co">#   This will provide the LLM information on what the function does,</span></span>
<span>    <span class="co">#   and how it should be used.</span></span>
<span>    </span>
<span>    <span class="va">location</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/match.arg.html" class="external-link">match.arg</a></span><span class="op">(</span><span class="va">location</span><span class="op">)</span></span>
<span>    <span class="va">unit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/match.arg.html" class="external-link">match.arg</a></span><span class="op">(</span><span class="va">unit</span><span class="op">)</span></span>
<span></span>
<span>    <span class="va">temperature_celcius</span> <span class="op">&lt;-</span> <span class="kw"><a href="https://rdrr.io/r/base/switch.html" class="external-link">switch</a></span><span class="op">(</span></span>
<span>      <span class="va">location</span>,</span>
<span>      <span class="st">"Amsterdam"</span> <span class="op">=</span> <span class="fl">32.5</span>,</span>
<span>      <span class="st">"Utrecht"</span> <span class="op">=</span> <span class="fl">19.8</span>,</span>
<span>      <span class="st">"Enschede"</span> <span class="op">=</span> <span class="fl">22.7</span></span>
<span>    <span class="op">)</span></span>
<span></span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="va">unit</span> <span class="op">==</span> <span class="st">"Celcius"</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="va">temperature_celcius</span><span class="op">)</span></span>
<span>    <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>      <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="va">temperature_celcius</span> <span class="op">*</span> <span class="fl">9</span><span class="op">/</span><span class="fl">5</span> <span class="op">+</span> <span class="fl">32</span><span class="op">)</span></span>
<span>    <span class="op">}</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="co"># Ask the LLM a question which can be answered with the function</span></span>
<span>  <span class="st">"Hi, what is the weather temperature in Enschede?"</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="reference/add_text.html">add_text</a></span><span class="op">(</span><span class="st">"I want to know the Celcius degrees."</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="reference/answer_as_integer.html">answer_as_integer</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="reference/add_tools.html">add_tools</a></span><span class="op">(</span><span class="va">temperature_in_location</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="reference/send_prompt.html">send_prompt</a></span><span class="op">(</span><span class="va">ollama</span>, verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; --- Sending message to LLM-provider: ---</span></span>
<span><span class="co">#&gt; Hi, what is the weather temperature in Enschede?</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; I want to know the Celcius degrees.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; If you need more information, you can call functions to help you.</span></span>
<span><span class="co">#&gt; To call a function, type:</span></span>
<span><span class="co">#&gt;   FUNCTION[&lt;function name here&gt;](&lt;argument 1&gt;, &lt;argument 2&gt;, etc...)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; The following functions are available:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; function name: temperature_in_location</span></span>
<span><span class="co">#&gt; description: Get the temperature in a location</span></span>
<span><span class="co">#&gt; arguments:</span></span>
<span><span class="co">#&gt;     - location: Location, must be one of: "Amsterdam", "Utrecht", "Enschede"</span></span>
<span><span class="co">#&gt;     - unit: Unit, must be one of: "Celcius", "Fahrenheit"</span></span>
<span><span class="co">#&gt; return value: The temperature in the specified location and unit</span></span>
<span><span class="co">#&gt; example usage: FUNCTION[temperature_in_location]("Amsterdam", "Fahrenheit")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; After you call a function, wait until you receive more information.</span></span>
<span><span class="co">#&gt; --- Received response from LLM-provider: ---</span></span>
<span><span class="co">#&gt; I'll use the provided function to get the current temperature in Enschede.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; FUNCTION[temperature_in_location]("Enschede", "Celcius")</span></span>
<span><span class="co">#&gt; --- Sending message to LLM-provider: ---</span></span>
<span><span class="co">#&gt; function called: temperature_in_location</span></span>
<span><span class="co">#&gt; arguments used: Enschede, Celcius</span></span>
<span><span class="co">#&gt; result: 22.7</span></span>
<span><span class="co">#&gt; --- Received response from LLM-provider: ---</span></span>
<span><span class="co">#&gt; So the current temperature in Enschede is 22.7 degrees Celsius.</span></span>
<span><span class="co">#&gt; --- Sending message to LLM-provider: ---</span></span>
<span><span class="co">#&gt; You must answer with only an integer (use no other characters).</span></span>
<span><span class="co">#&gt; --- Received response from LLM-provider: ---</span></span>
<span><span class="co">#&gt; 22</span></span>
<span><span class="co">#&gt; [1] 22</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="creating-your-own-prompt-wrappers">Creating your own prompt wrappers<a class="anchor" aria-label="anchor" href="#creating-your-own-prompt-wrappers"></a>
</h3>
<p>Under the hood, prompts are just lists of a base prompt (a string) and a series of prompt wrappers.</p>
<p>You can thus create a function which takes a prompt and appends a new prompt wrapper to it.</p>
<p>Take a look at the source code for function <code>add_text</code>:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">add_text</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">prompt_wrap_or_list</span>, <span class="va">text</span>, <span class="va">sep</span> <span class="op">=</span> <span class="st">"\n\n"</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">prompt_list</span> <span class="op">&lt;-</span> <span class="fu">validate_prompt_list</span><span class="op">(</span><span class="va">prompt_wrap_or_list</span><span class="op">)</span></span>
<span></span>
<span>  <span class="va">new_wrap</span> <span class="op">&lt;-</span> <span class="fu">create_prompt_wrap</span><span class="op">(</span></span>
<span>    modify_fn <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">original_prompt_text</span>, <span class="va">modify_fn_args</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="va">text</span> <span class="op">&lt;-</span> <span class="va">modify_fn_args</span><span class="op">$</span><span class="va">text</span></span>
<span>      <span class="va">sep</span> <span class="op">&lt;-</span> <span class="va">modify_fn_args</span><span class="op">$</span><span class="va">sep</span></span>
<span>      <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="va">original_prompt_text</span>, <span class="va">text</span>, sep <span class="op">=</span> <span class="va">sep</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="op">}</span>,</span>
<span>    modify_fn_args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>text <span class="op">=</span> <span class="va">text</span>, sep <span class="op">=</span> <span class="va">sep</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">prompt_list</span>, <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">new_wrap</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>More complex prompt wrappers may also add extraction and validation functions. Take a look at the source code for function <code>answer_as_integer</code>:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">answer_as_integer</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span></span>
<span>    <span class="va">prompt_wrap_or_list</span>, <span class="va">min</span> <span class="op">=</span> <span class="cn">NULL</span>, <span class="va">max</span> <span class="op">=</span> <span class="cn">NULL</span>, <span class="va">add_instruction_to_prompt</span> <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">prompt_list</span> <span class="op">&lt;-</span> <span class="fu">validate_prompt_list</span><span class="op">(</span><span class="va">prompt_wrap_or_list</span><span class="op">)</span></span>
<span></span>
<span>  <span class="va">new_wrap</span> <span class="op">&lt;-</span> <span class="fu">create_prompt_wrap</span><span class="op">(</span></span>
<span>    modify_fn <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">original_prompt_text</span>, <span class="va">modify_fn_args</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="va">min</span> <span class="op">&lt;-</span> <span class="va">modify_fn_args</span><span class="op">$</span><span class="va">min</span></span>
<span>      <span class="va">max</span> <span class="op">&lt;-</span> <span class="va">modify_fn_args</span><span class="op">$</span><span class="va">max</span></span>
<span></span>
<span>      <span class="va">new_prompt_text</span> <span class="op">&lt;-</span> <span class="va">original_prompt_text</span></span>
<span></span>
<span>      <span class="kw">if</span> <span class="op">(</span><span class="va">add_instruction_to_prompt</span><span class="op">)</span> <span class="op">{</span></span>
<span>        <span class="va">new_prompt_text</span> <span class="op">&lt;-</span> <span class="fu">glue</span><span class="fu">::</span><span class="fu"><a href="https://glue.tidyverse.org/reference/glue.html" class="external-link">glue</a></span><span class="op">(</span></span>
<span>          <span class="st">"{new_prompt_text}</span></span>
<span><span class="st"></span></span>
<span><span class="st">          You must answer with only an integer (use no other characters)."</span></span>
<span>        <span class="op">)</span></span>
<span></span>
<span>        <span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html" class="external-link">is.null</a></span><span class="op">(</span><span class="va">min</span><span class="op">)</span> <span class="op">&amp;&amp;</span> <span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html" class="external-link">is.null</a></span><span class="op">(</span><span class="va">max</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>          <span class="va">new_prompt_text</span> <span class="op">&lt;-</span> <span class="fu">glue</span><span class="fu">::</span><span class="fu"><a href="https://glue.tidyverse.org/reference/glue.html" class="external-link">glue</a></span><span class="op">(</span></span>
<span>            <span class="st">"{new_prompt_text}</span></span>
<span><span class="st">            Enter an integer between {min} and {max}."</span></span>
<span>          <span class="op">)</span></span>
<span>        <span class="op">}</span> <span class="kw">else</span> <span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html" class="external-link">is.null</a></span><span class="op">(</span><span class="va">min</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>          <span class="va">new_prompt_text</span> <span class="op">&lt;-</span> <span class="fu">glue</span><span class="fu">::</span><span class="fu"><a href="https://glue.tidyverse.org/reference/glue.html" class="external-link">glue</a></span><span class="op">(</span></span>
<span>            <span class="st">"{new_prompt_text}</span></span>
<span><span class="st">            Enter an integer greater than or equal to {min}."</span></span>
<span>          <span class="op">)</span></span>
<span>        <span class="op">}</span> <span class="kw">else</span> <span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html" class="external-link">is.null</a></span><span class="op">(</span><span class="va">max</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>          <span class="va">new_prompt_text</span> <span class="op">&lt;-</span> <span class="fu">glue</span><span class="fu">::</span><span class="fu"><a href="https://glue.tidyverse.org/reference/glue.html" class="external-link">glue</a></span><span class="op">(</span></span>
<span>            <span class="st">"{new_prompt_text}</span></span>
<span><span class="st">            Enter an integer less than or equal to {max}."</span></span>
<span>          <span class="op">)</span></span>
<span>        <span class="op">}</span></span>
<span>      <span class="op">}</span></span>
<span></span>
<span>      <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="va">new_prompt_text</span><span class="op">)</span></span>
<span>    <span class="op">}</span>,</span>
<span>    </span>
<span>    extraction_functions <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>      <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>        <span class="va">extracted</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/warning.html" class="external-link">suppressWarnings</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/integer.html" class="external-link">as.integer</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span>        <span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html" class="external-link">is.na</a></span><span class="op">(</span><span class="va">extracted</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>          <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu"><a href="reference/create_llm_feedback.html">create_llm_feedback</a></span><span class="op">(</span><span class="st">"You must answer with only an integer (use no other characters)."</span><span class="op">)</span><span class="op">)</span></span>
<span>        <span class="op">}</span></span>
<span>        <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="va">extracted</span><span class="op">)</span></span>
<span>      <span class="op">}</span></span>
<span>    <span class="op">)</span>,</span>
<span>    </span>
<span>    validation_functions <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>      <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>        <span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html" class="external-link">is.null</a></span><span class="op">(</span><span class="va">min</span><span class="op">)</span> <span class="op">&amp;&amp;</span> <span class="va">x</span> <span class="op">&lt;</span> <span class="va">min</span><span class="op">)</span> <span class="op">{</span></span>
<span>          <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu"><a href="reference/create_llm_feedback.html">create_llm_feedback</a></span><span class="op">(</span><span class="fu">glue</span><span class="fu">::</span><span class="fu"><a href="https://glue.tidyverse.org/reference/glue.html" class="external-link">glue</a></span><span class="op">(</span></span>
<span>            <span class="st">"The number should be greater than or equal to {min}."</span></span>
<span>          <span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>        <span class="op">}</span></span>
<span>        <span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html" class="external-link">is.null</a></span><span class="op">(</span><span class="va">max</span><span class="op">)</span> <span class="op">&amp;&amp;</span> <span class="va">x</span> <span class="op">&gt;</span> <span class="va">max</span><span class="op">)</span> <span class="op">{</span></span>
<span>          <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu"><a href="reference/create_llm_feedback.html">create_llm_feedback</a></span><span class="op">(</span><span class="fu">glue</span><span class="fu">::</span><span class="fu"><a href="https://glue.tidyverse.org/reference/glue.html" class="external-link">glue</a></span><span class="op">(</span></span>
<span>            <span class="st">"The number should be less than or equal to {max}."</span></span>
<span>          <span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>        <span class="op">}</span></span>
<span></span>
<span>        <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span>      <span class="op">}</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">prompt_list</span>, <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">new_wrap</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>They key difference between an extraction and validation function is that an extraction function alters the LLM’s response and passes on the altered response to next extraction and/or validation functions, and eventually to the return statement of send_prompt (if extractions and validations are succesful). A validation function, on the other hand, only checks if the LLM’s response passes a logical test. Both extraction and validation functions can return feedback to the LLM.</p>
<p>For more information, on what you can do with prompt wrappers, see the documentation of the <code>prompt_wrap</code> class creator function: <code>create_prompt_wrap</code>. For examples of prompt wrapper functions, see, for instance the documentation and source code of <code>add_text</code>, <code>answer_as_integer</code>, <code>set_mode_chainofthought</code>, and <code>add_tools</code>.</p>
</div>
</div>
<div class="section level2">
<h2 id="more-information-and-contributing">More information and contributing<a class="anchor" aria-label="anchor" href="#more-information-and-contributing"></a>
</h2>
<p><code>tidyprompt</code> is under active development by Luka Koning (<a href="mailto:l.koning@kennispunttwente.nl" class="email">l.koning@kennispunttwente.nl</a>) and Tjark van de Merwe (<a href="mailto:t.vandemerwe@kennispunttwente.nl" class="email">t.vandemerwe@kennispunttwente.nl</a>). Note that in this stage, the package is not yet fully stable and its architecture is subject to change.</p>
<p>If you encounter issues, please open an issue in the GitHub repository. You are welcome to contribute to the package by opening a pull request. If you have any questions or suggestions, you can also reach us via e-mail.</p>
</div>
</div>
  </main><aside class="col-md-3"><div class="links">
<h2 data-toc-skip>Links</h2>
<ul class="list-unstyled">
<li><a href="https://github.com/tjarkvandemerwe/tidyprompt/" class="external-link">Browse source code</a></li>
<li><a href="https://github.com/tjarkvandemerwe/tidyprompt/issues" class="external-link">Report a bug</a></li>
</ul>
</div>

<div class="license">
<h2 data-toc-skip>License</h2>
<ul class="list-unstyled">
<li><a href="LICENSE.html">Full license</a></li>
<li><small>GPL (&gt;= 3) | file <a href="LICENSE-text.html">LICENSE</a></small></li>
</ul>
</div>


<div class="citation">
<h2 data-toc-skip>Citation</h2>
<ul class="list-unstyled">
<li><a href="authors.html#citation">Citing tidyprompt</a></li>
</ul>
</div>

<div class="developers">
<h2 data-toc-skip>Developers</h2>
<ul class="list-unstyled">
<li>Luka Koning <br><small class="roles"> Author, maintainer, copyright holder </small>  </li>
<li>Tjark Van de Merwe <br><small class="roles"> Author, copyright holder </small>  </li>
</ul>
</div>



  </aside>
</div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Luka Koning, Tjark Van de Merwe.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
